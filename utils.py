# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13uVA8g6FZq1KLvDxbVtgbp1trtKd_0W8
"""

import os
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.summarize import load_summarize_chain
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI


# Load API key from environment variable (Hugging Face Secrets)
openai_api_key = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = openai_api_key

# Load and process docs
loader = TextLoader("combined_text.txt")
documents = loader.load()

# Split text into chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs = text_splitter.split_documents(documents)

embedding = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(docs, embedding)
retriever = vectorstore.as_retriever()

llm = ChatOpenAI(model_name="gpt-4", temperature=0)
summary_chain = load_summarize_chain(llm, chain_type="map_reduce")

def summarize_retrieved(query):
    docs = retriever.get_relevant_documents(query)
    return summary_chain.run(docs)


summarized_tool = Tool(
    name="SummarizedDocSearch",
    func=summarize_retrieved,
    description="Use this tool to retrieve and summarize relevant information from the knowledge base."
)

tools = [summarized_tool]


agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # lets LLM decide how to use tools
    verbose=True
)
